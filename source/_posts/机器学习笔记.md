---
title: 机器学习笔记
date: 2022-01-04 11:02:15
categories: AI
tags: 机器学习
feature: true
cover: https://source.unsplash.com/yQnyP1g5zl4/1200x628
---
# Boosting & Bagging

用抽样的方式从原始样本中进行有放回的多次抽样（或者是抽特征），这种方法叫做Bootstraping，抽取k次每次抽取n个样本，这样就生成了k个样本容量为n的数据集。原始数据集中的样本可能是多次被抽到也可能是没有被抽到。

boosting与bagging不同的是，bagging是多个模型“并行”，voting决定结果；而boosting是多个模型串行，通过多个模型的结果相加得到最终的结果。

AdaBoosting方式每次使用的是全部的样本，每轮训练改变样本的权重。下一轮训练的目标是找到一个函数f 来拟合上一轮的残差。当残差足够小或者达到设置的最大迭代次数则停止。Boosting会减小在上一轮训练正确的样本的权重，增大错误样本的权重。（对的残差小，错的残差大）

梯度提升的Boosting方式是使用代价函数对上一轮训练出的模型函数f的偏导来拟合残差。